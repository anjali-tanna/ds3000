{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 HW 4\n",
    "\n",
    "Due: Sun Mar 6 @ 11:59 PM EST\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to [gradescope](https://www.gradescope.com/courses/337250).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the `ipynb` file to gradescope.\n",
    "\n",
    "### Tips for success\n",
    "- Start early\n",
    "- Make use of [Piazza](https://course.ccs.neu.edu/ds3000/admin.html#piazza-discussion-forum)\n",
    "- Make use of [Office Hours](https://course.ccs.neu.edu/ds3000/office_hours.html)\n",
    "- Remember that [Documentation / style counts for credit](https://course.ccs.neu.edu/ds3000/style_guide.html)\n",
    "- Under no circumstances may one student view or share their ungraded homework or quiz with another student [(see also)](https://course.ccs.neu.edu/ds3000/syllabus.html#academic-integrity-and-conduct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview: \"Good\" songs\n",
    "\n",
    "You will start **(but not complete)** a comparison of \"good\" songs as determined by two websites.\n",
    " - The [best music](https://pitchfork.com/reviews/best/tracks/) according to [Pitchfork](https://pitchfork.com/)\n",
    "     - new (mostly independent) music\n",
    " - The [best music](https://www.billboard.com/articles/news/list/9494940/best-songs-2020-top-100/) according to [Billboard](billboard.com)\n",
    "     - \"good\" defined based on record sales    \n",
    "    \n",
    "The analysis pipeline will\n",
    " - scrape top songs from pitchfork\n",
    " - scrape top songs from billboard\n",
    " - query the Spotify API to get popularity rankings on each song\n",
    " - produce the histogram shown below\n",
    "\n",
    "<img src=\"https://i.ibb.co/0Z8VPQV/Screenshot-from-2021-02-25-15-02-18.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Program design (28 points)\n",
    "The task above may be completed by running the following script.  Note that `clean_pitchfork()` and `clean_billboard()` both return dataframes with columns `track` and `artist`.\n",
    "\n",
    "```python\n",
    "url_pitchfork = 'https://pitchfork.com/reviews/best/tracks/'\n",
    "url_billboard = 'https://www.billboard.com/articles/news/list/9494940/best-songs-2020-top-100/'\n",
    "spot_api_key = '<spotify-key-here>'\n",
    "\n",
    "# get html of each set of songs\n",
    "html_str_pitchfork = get_url(url_pitchfork)\n",
    "html_str_billboard = get_url(url_billboard)\n",
    "\n",
    "# web scrape tracks from html of pages\n",
    "df_pitchfork = clean_pitchfork(html_str_pitchfork)\n",
    "df_billboard = clean_billboard(html_str_billboard)\n",
    "\n",
    "# record source of each track\n",
    "df_pitchfork['source'] = 'pitchfork'\n",
    "df_billboard['source'] = 'billboard'\n",
    "\n",
    "# concatenate all tracks\n",
    "df_track = pd.concat((df_pitchfork, df_billboard), axis=0)\n",
    "\n",
    "# query spotify API for popularity of each track\n",
    "df_track = get_popularity(df_track, api_key=spot_api_key)\n",
    "\n",
    "# plot histogram of popularity per source\n",
    "hist_feat(df_track, feat='popularity')\n",
    "```\n",
    "\n",
    "For each of the functions listed in sub-parts below, write a function statement and docstring.  \n",
    "\n",
    "The \"work\" of this problem is being able to clearly define the inputs and outputs as needed so the pipeline produces the desired result.  Be sure to describe the inputs / outputs of each function by writing the function statement / docstring as shown in the example below:\n",
    "\n",
    "```python\n",
    "\n",
    "def some_fnc(input0, input1):\n",
    "    \"\"\" this function does a thing!\n",
    "    \n",
    "    Args:\n",
    "        input0 (type of input0): input0 is a ...\n",
    "        input1 (type of input1): input1 is ...\n",
    "        \n",
    "    Returns:\n",
    "        output0 (type of output0): output0 is ...\n",
    "    \"\"\"\n",
    "    # \"pass\" allow us to end an indentation body without causing\n",
    "    # any errors when from the python interpreter\n",
    "    pass\n",
    "```\n",
    "\n",
    "### Part 1.1: `get_url()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Part 1.1\n",
    "def get_url(url):\n",
    "    \"\"\" gets html associated with a url \n",
    "    \n",
    "    Args:\n",
    "        url (str): url website to look up\n",
    "        \n",
    "    Returns:\n",
    "        html_str (str): html associated with this url\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2: `clean_pitchfork()`\n",
    "(No need to write a seperate docstring for `clean_billboard()`, as it has the same inputs / outputs as `clean_pitchfork()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Part 1.2\n",
    "def clean_pitchfork(html_str):\n",
    "    \"\"\" scrapes artists / track from a pitchfork page\n",
    "    \n",
    "    ex:\n",
    "    https://pitchfork.com/reviews/best/tracks/?page=1\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html of pitchfork page\n",
    "        \n",
    "    Returns:\n",
    "        df_pitch (DataFrame): each row is a song.  \n",
    "            contains columns 'artist', 'track'  \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.3 `get_popularity()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Part 1.3\n",
    "def get_popularity(df_track, api_key):\n",
    "    \"\"\" queries spotify API for popularity of all songs in df_track\n",
    "    \n",
    "    Args:\n",
    "        df_track (DataFrame): a dataframe which contains (at least)\n",
    "            columns: artist & track.  one row per song\n",
    "        api_key (str): api key of spotify API\n",
    "        \n",
    "    Returns:\n",
    "        df_track (DataFrame): each row is a song.  \n",
    "            contains columns 'artist', 'track' and \n",
    "            `popularity` as well as other columns in\n",
    "            the input df_track.  note: this is a copy\n",
    "            of the input (doesn't overwrite)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.4: `hist_feat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution Part 1.4\n",
    "def hist_feat(df, feat):\n",
    "    \"\"\" produces a histogram of feat per unique source\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): contains a column source\n",
    "        feat (str): some other column of input df\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Build `get_url()` (6 points)\n",
    "When you're done, check that it works by outputting to the jupyter notebook the `html_str` associated with input:\n",
    "```python\n",
    "url='https://www.billboard.com/media/lists/best-songs-2020-top-100-9494940/'\n",
    "```\n",
    "\n",
    "Tip: you can click or double click the margin just below `Out[x]` to hide / limit this output ... the full html string can be quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution Part 2\n",
    "import requests\n",
    "\n",
    "def get_url(url):\n",
    "    \"\"\" gets html associated with a url \n",
    "    \n",
    "    Args:\n",
    "        url (str): url website to look up\n",
    "        \n",
    "    Returns:\n",
    "        html_str (str): html associated with this url\n",
    "    \"\"\"\n",
    "    return requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/media/lists/best-songs-2020-top-100-9494940/'\n",
    "get_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- describe your pipeline here -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3:  Build `clean_pitchfork()`  (28 points)\n",
    "\n",
    "Build `clean_pitchfork()`\n",
    "\n",
    "- You may skip the initial track \"Porridge Radio\"\n",
    "- Be sure to remove the double quotes: `“` `”` from the track names.  Note these are not the typical <shift + comma> character, copy and paste them from above to ensure you get the proper string match.\n",
    "\n",
    "When you're done, check that it works by outputting to the jupyter notebook the first few rows of a DataFrame of Pitchfork songs:\n",
    "```python\n",
    "url = 'https://pitchfork.com/reviews/best/tracks/?page=1'\n",
    "html_str = get_url(url)\n",
    "df_pitch = clean_pitchfork(html_str)\n",
    "df_pitch.head()\n",
    "```\n",
    "\n",
    "which should show (as of Feb 22 @ 1PM):\n",
    "\n",
    "| artist |           track |                                     source |           |\n",
    "|-------:|----------------:|-------------------------------------------:|-----------|\n",
    "|      0 |           yeule |                           Bites on My Neck | pitchfork |\n",
    "|      1 |       Two Shell |                                       home | pitchfork |\n",
    "|      2 |   Nilüfer Yanya |                               Midnight Sun | pitchfork |\n",
    "|      3 |        Soul Glo | Jump!! (Or Get Jumped!!!)((By the Future)) | pitchfork |\n",
    "|      4 | Earl Sweatshirt |                                       2010 | pitchfork |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def clean_pitchfork(html_str):\n",
    "    \"\"\" scraps artists / track from a pitchfork page\n",
    "    \n",
    "    ex:\n",
    "    https://pitchfork.com/reviews/best/tracks/?page=1\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html of pitchfork page\n",
    "        \n",
    "    Returns:\n",
    "        df_pitch (DataFrame): each row is a song.  \n",
    "            contains columns 'artist', 'track' and \n",
    "            'source' (source is always 'pitchfork')    \n",
    "    \"\"\"\n",
    "    # build soup\n",
    "    soup = BeautifulSoup(html_str)\n",
    "    \n",
    "    df_pitch = pd.DataFrame()\n",
    "    for song in soup.find_all('div', class_='track-collection-item'):\n",
    "        # extract artist\n",
    "        artist = song.find_all('ul', class_='artist-list')[0].text\n",
    "        \n",
    "        #extract track\n",
    "        track = song.find_all('h2', class_='track-collection-item__title')[0].text\n",
    "        \n",
    "        # discard all directional double quotes\n",
    "        track = track.replace('“', '')\n",
    "        track = track.replace('”', '')\n",
    "        \n",
    "        # collect song data in dataframe\n",
    "        song_dict = {'artist': artist, \n",
    "                     'track': track,\n",
    "                     'source': 'pitchfork'}\n",
    "        df_pitch = df_pitch.append(song_dict, ignore_index=True)\n",
    "        \n",
    "    return df_pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 3\n",
    "url = 'https://pitchfork.com/reviews/best/tracks/?page=1'\n",
    "html_str = get_url(url)\n",
    "df_pitch = clean_pitchfork(html_str)\n",
    "df_pitch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Managing the scrolling on Pitchfork's website (10 points)\n",
    "\n",
    "Notice that as one scrolls to the bottom of the pitchfork page the `?page=x` counter increments.  [Try it yourself](https://pitchfork.com/reviews/best/tracks/).  Just as we did with the API work, we can modify the URL to get different sets of songs from Pitchfork.\n",
    "\n",
    "Write a script which scrolls through 10 pages of Pitchfork's music reccomendations and collects all the songs you find into a single `df_pitch` DataFrame.  Be sure to use the functions you've created above.\n",
    "\n",
    "Validation: We found 56 songs running this on Feb 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 4\n",
    "\n",
    "max_page = 10\n",
    "\n",
    "df_pitch = pd.DataFrame()\n",
    "for page_idx in range(1, max_page + 1):\n",
    "    # build url of a given page of pitchfork music\n",
    "    url = f'https://pitchfork.com/reviews/best/tracks/?page={page_idx}'\n",
    "    \n",
    "    # get pitchfork page\n",
    "    html_str = get_url(url)\n",
    "    \n",
    "    # process to dataframe\n",
    "    df_pitch_page = clean_pitchfork(html_str)\n",
    "    \n",
    "    # collect each page in one common dataframe: df_pitch\n",
    "    df_pitch = df_pitch.append(df_pitch_page, ignore_index=True)\n",
    "\n",
    "# output shape to jupyter notebook (56 songs total when I ran this Feb 25)\n",
    "df_pitch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5 (28 points)\n",
    "\n",
    "<img src=\"https://i.ibb.co/wht5NB0/Screenshot-from-2022-02-23-05-14-26.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Write a function, `clean_quote()` which scrapes all the quotes from https://www.brainyquote.com/topics/websites-quotes:\n",
    "\n",
    "```python\n",
    "url = 'https://www.brainyquote.com/topics/websites-quotes'\n",
    "html = get_url(url)\n",
    "df_quote = clean_quote(html)\n",
    "df_quote.head()\n",
    "```\n",
    "\n",
    "gives:\n",
    "\n",
    "|   |          author |                                              text |\n",
    "|--:|----------------:|--------------------------------------------------:|\n",
    "| 0 |  Shreya Ghoshal | I'm not a gadget freak, so to say. I own an iP... |\n",
    "| 1 | Anthony Carmona | Social media websites are no longer performing... |\n",
    "| 2 |    M. J. Hyland | As is the case for many people with multiple s... |\n",
    "| 3 |     Brie Larson | There are so many opportunities to learn thing... |\n",
    "| 4 |      Ben Barnes |        There are loads of websites devoted to me. |\n",
    "\n",
    "**Extra Credit (up to +3 points)**: Navigate to each quote's own webpage and you'll find more information:\n",
    "\n",
    "<img src=\"https://i.ibb.co/ZKQS1ks/Screenshot-from-2022-02-23-05-14-37.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Store the tags associated with each quote too.  For example, Bill Gate's quote above has tags: `'truth'`, `'government'`, `'internet'`, `'never'` and '`hard'`.  Think carefully about how you store the tags so that one may easily understand how many times each tag (e.g. `'internet'`) appears in your dataframe with simple pandas manipulations (hint: look tags are stored for boardgames in `Out [3]` of the `ipynb` for the [board game example project](https://course.ccs.neu.edu/ds3000/proj_example.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 5\n",
    "def clean_quote(html_str, collect_tags=False):\n",
    "    \"\"\" cleans brainy quote quotes\n",
    "    \n",
    "    ex: https://www.brainyquote.com/topics/websites-quotes\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html of website\n",
    "        collect_tags (bool): toggles whether tags are \n",
    "            collected on each quote\n",
    "        \n",
    "    Returns:\n",
    "        df_quote (pd.DataFrame): contains columns author,\n",
    "            text and (potentially ) a column for every tag (e.g.\n",
    "            Communication, Family, Positive, Love...).\n",
    "            values of a tag column are 1 where tag \n",
    "            applies to the row's quote, otherwise they're 0\n",
    "    \"\"\"\n",
    "    # build soup from html_str\n",
    "    soup = BeautifulSoup(html_str)\n",
    "\n",
    "    df_quote = pd.DataFrame()\n",
    "    for quote in soup.find_all('div', class_='grid-item'):\n",
    "        \n",
    "        if 'm-ad-brick' in quote.attrs['class']:\n",
    "            # ad, skip this one\n",
    "            continue\n",
    "\n",
    "        # get author and text\n",
    "        a_list = quote.find_all('a')\n",
    "        author = a_list[1].text\n",
    "        text = a_list[0].text.strip()\n",
    "\n",
    "        quote_dict = {'author': author,\n",
    "                      'text': text}\n",
    "\n",
    "        if collect_tags:\n",
    "            # ex credit: get quote tags\n",
    "            # find website of individual quote\n",
    "            href = 'https://www.brainyquote.com' + quote.a.attrs['href']\n",
    "            quote_html = get_url(href)\n",
    "            quote_soup = BeautifulSoup(quote_html)\n",
    "\n",
    "            # collect tags\n",
    "            tags = quote_soup.find_all('div', class_='kw-box')[0].text\n",
    "            for tag in tags.strip().split('\\n'):\n",
    "                 quote_dict[tag] = 1\n",
    "\n",
    "        # add quote to dataframe\n",
    "        df_quote = df_quote.append(quote_dict, ignore_index=True)\n",
    "\n",
    "    if collect_tags:\n",
    "        # ex credit: all NaNs are where tag wasn't observed, map them to 0\n",
    "        df_quote = df_quote.fillna(0)\n",
    "        \n",
    "    return df_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 5\n",
    "url = 'https://www.brainyquote.com/topics/websites-quotes'\n",
    "html = get_url(url)\n",
    "df_quote = clean_quote(html)\n",
    "df_quote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Solution) Extra Credit Analysis: Which tags are often associated with websites?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 5\n",
    "url = 'https://www.brainyquote.com/topics/websites-quotes'\n",
    "html = get_url(url)\n",
    "df_quote = clean_quote(html, collect_tags=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution part 5\n",
    "# take the mean of all features (finds average quotes with each tag)\n",
    "df_quote_mean = df_quote.mean()\n",
    "\n",
    "# display top 10 most common tags in website quotes:\n",
    "# (People = .2166667 implies that about 20% of website quotes have the tag \"People\")\n",
    "df_quote_mean.sort_values(ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
